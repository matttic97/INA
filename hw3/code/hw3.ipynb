{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3OBYK9qdZHS",
    "outputId": "0df0b0c7-786f-4df0-d848-51942dedd76e"
   },
   "outputs": [],
   "source": [
    "# !pip install cdlib\n",
    "# !pip install infomap\n",
    "# !pip install wurlitzer\n",
    "!pip install leidenalg\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import node_classification\n",
    "import random\n",
    "from cdlib import algorithms, evaluation, NodeClustering\n",
    "from community import community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sWU8FrYrkhp"
   },
   "source": [
    "## 2. Who’s the winner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNe-iAYbrn7I"
   },
   "source": [
    "### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "sxTyWpG9dcfm",
    "outputId": "4064e607-66dd-464b-d459-c83640488cdd"
   },
   "outputs": [],
   "source": [
    "def build_synhtetic_graph(mu = 0.5):\n",
    "    G = nx.Graph(name = \"girvan_newman\")\n",
    "    n = 72\n",
    "    cluster_div = 24\n",
    "    for i in range(n):\n",
    "        G.add_node(i, cluster = i // cluster_div + 1)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if G.nodes[i]['cluster'] == G.nodes[j]['cluster']:\n",
    "                if random.random() < 20 * (1 - mu) / (cluster_div-1):\n",
    "                    G.add_edge(i, j)\n",
    "            else:\n",
    "                if random.random() < 20 * mu / (n-cluster_div):\n",
    "                    G.add_edge(i, j)\n",
    "    return G\n",
    "\n",
    "def compare_on_synthetic(algo_fn, mus, iter_num=10):\n",
    "    nmis = []\n",
    "    for mu in mus:\n",
    "        NMI = 0\n",
    "        for _ in range(iter_num):\n",
    "            G = build_synhtetic_graph(mu)\n",
    "            clustered_G = algo_fn(G)\n",
    "            partition = get_graph_ideal_partition(G) \n",
    "            NMI += clustered_G.normalized_mutual_information(partition).score / iter_num\n",
    "        nmis.append(NMI)\n",
    "        print(\"mu={:.2f}, NMI: {:5.3f}\".format(mu, NMI))\n",
    "    return nmis\n",
    "        \n",
    "def get_graph_ideal_partition(G):\n",
    "    P = {}\n",
    "    for node in G.nodes(data = True):\n",
    "        if node[1]['cluster'] not in P:\n",
    "            P[node[1]['cluster']] = []\n",
    "        P[node[1]['cluster']].append(node[0])\n",
    "    node_clusters = P.values()\n",
    "    return NodeClustering(list(node_clusters), G, 'Ideal')\n",
    "\n",
    "def run():\n",
    "    iter_num = 25\n",
    "    mus = [0.1 * i for i in range(0, 6)]\n",
    "    algs = {\n",
    "        \"Louvain\": algorithms.louvain,\n",
    "        \"Infomap\": algorithms.infomap,\n",
    "        \"Walktrap\": algorithms.walktrap\n",
    "    }\n",
    "    fig = plt.figure()\n",
    "    plt.xlabel('µ')\n",
    "    plt.ylabel('Normalized mutual information')\n",
    "    plt.xticks(mus)\n",
    "\n",
    "    for algo_name in algs:\n",
    "        print('ALGORITHM:', algo_name)\n",
    "        nmis = compare_on_synthetic(algs[algo_name], mus, iter_num)\n",
    "        plt.plot(mus, nmis, label=algo_name)\n",
    "        print('======================'*3)\n",
    "        \n",
    "    plt.savefig(\"images/2_i.jpg\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaIi8dd1rrZb"
   },
   "source": [
    "### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "zhCLnNQrdpqc",
    "outputId": "108c9fb7-da01-44d2-ed80-7e1899866cb7"
   },
   "outputs": [],
   "source": [
    "def read_net(folder, graph_name):\n",
    "    file_name = graph_name + '.net'\n",
    "    G = nx.MultiGraph(name = file_name)\n",
    "    with open(os.path.join(folder, file_name), 'r', encoding='utf8') as f:\n",
    "        f.readline()\n",
    "        # add nodes\n",
    "        for line in f:\n",
    "            if line.startswith(\"*\"):\n",
    "                break\n",
    "            else:\n",
    "                node_info = line.split(\"\\\"\")\n",
    "                node = int(node_info[0]) - 1\n",
    "                label = node_info[1]\n",
    "                cluster = int(node_info[2]) if len(node_info) > 2 and len(node_info[2].strip()) > 0 else 0\n",
    "                G.add_node(node, label=label, cluster=cluster)\n",
    "\n",
    "        # add edges\n",
    "        for line in f:\n",
    "            node1_str, node2_str = line.split()[:2]\n",
    "            G.add_edge(int(node1_str)-1, int(node2_str)-1)\n",
    "    return G\n",
    "\n",
    "def compare_on_lrf(algo_fn, mus, iter_num=10):\n",
    "    nmis = []\n",
    "    for mu in mus:\n",
    "        NMI = 0\n",
    "        for i in range(iter_num):\n",
    "            G = read_net(\"data/LFR/\", \"LFR_0{}_{}\".format(int(mu*10), i))\n",
    "            clustered_G = algo_fn(G)\n",
    "            partition = get_graph_ideal_partition(G) \n",
    "            NMI += clustered_G.normalized_mutual_information(partition).score / iter_num\n",
    "        nmis.append(NMI)\n",
    "        print(\"mu={:.2f}, NMI: {:5.3f}\".format(mu, NMI))\n",
    "    return nmis\n",
    "        \n",
    "def get_graph_ideal_partition(G):\n",
    "    P = {}\n",
    "    for node in G.nodes(data = True):\n",
    "        if node[1]['cluster'] not in P:\n",
    "            P[node[1]['cluster']] = []\n",
    "        P[node[1]['cluster']].append(node[0])\n",
    "    node_clusters = P.values()\n",
    "    return NodeClustering(list(node_clusters), G, 'Ideal')\n",
    "\n",
    "def run():\n",
    "    iter_num = 25\n",
    "    mus = [0.2 * i for i in range(0, 5)]\n",
    "    algs = {\n",
    "        \"Louvain\": algorithms.louvain,\n",
    "        \"Infomap\": algorithms.infomap,\n",
    "        \"Walktrap\": algorithms.walktrap\n",
    "    }\n",
    "    fig = plt.figure()\n",
    "    plt.xlabel('µ')\n",
    "    plt.ylabel('Normalized mutual information')\n",
    "    plt.xticks(mus)\n",
    "\n",
    "    for algo_name in algs:\n",
    "        print('ALGORITHM:', algo_name)\n",
    "        nmis = compare_on_lrf(algs[algo_name], mus, iter_num)\n",
    "        plt.plot(mus, nmis, label=algo_name)\n",
    "        print('======================'*3)\n",
    "        \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"images/2_ii.jpg\")\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5282a6Ekrt2N"
   },
   "source": [
    "### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "ys4jHQ17fHzC",
    "outputId": "86515f65-f907-4301-b2dc-59ff57d7bb5c"
   },
   "outputs": [],
   "source": [
    "def compare_on_random(algo_fn, avg_degrees, iter_num=10):\n",
    "    nvis = []\n",
    "    n = 1000\n",
    "    for avg_degree in avg_degrees:\n",
    "        NVI = 0\n",
    "        for i in range(iter_num):\n",
    "            G = nx.gnm_random_graph(n, avg_degree*n/2)\n",
    "            clustered_G = algo_fn(G)\n",
    "            partition = NodeClustering([[r] for r in range(n)], graph=G, method_name=\"rand_graph\")\n",
    "            NVI += clustered_G.variation_of_information(partition).score / math.log(n)\n",
    "        NVI /= iter_num\n",
    "        nvis.append(NVI)\n",
    "        print(\"avg degree={:.2f}, NVI: {:5.3f}\".format(avg_degree, NVI))\n",
    "    return nvis\n",
    "\n",
    "def run():\n",
    "    iter_num = 25\n",
    "    avg_degrees = [8 * i for i in range(1, 6)]\n",
    "    algs = {\n",
    "        \"Louvain\": algorithms.louvain,\n",
    "        \"Infomap\": algorithms.infomap,\n",
    "        \"Walktrap\": algorithms.walktrap\n",
    "    }\n",
    "    fig = plt.figure()\n",
    "    plt.xlabel('µ')\n",
    "    plt.ylabel('Normalized variation of information')\n",
    "    plt.xticks(avg_degrees)\n",
    "\n",
    "    for algo_name in algs:\n",
    "        print('ALGORITHM:', algo_name)\n",
    "        nvis = compare_on_random(algs[algo_name], avg_degrees, iter_num)\n",
    "        plt.plot(avg_degrees, nvis, label=algo_name)\n",
    "        print('======================'*3)\n",
    "        \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"images/2_iii.jpg\")\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enUKudYOrv1x"
   },
   "source": [
    "### (iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1x3vrkmr6B9",
    "outputId": "2e4ff702-529a-4b9a-d329-f0d6238466d5"
   },
   "outputs": [],
   "source": [
    "def compare_on_dolphins(G, algo_fn, iter_num=25):\n",
    "    N = G.number_of_nodes()\n",
    "    communities = []\n",
    "    for i in range(iter_num):\n",
    "        clustered_G = algo_fn(G)\n",
    "        communities.append(clustered_G)\n",
    "    NVI = 0\n",
    "    for i in range(iter_num):\n",
    "        for j in range(i+1, iter_num):\n",
    "            NVI += communities[i].variation_of_information(communities[j]).score / math.log(N)\n",
    "    NVI /= iter_num*(iter_num-1)/2\n",
    "    print(\"NVI: {:5.3f}\".format(NVI))\n",
    "    return NVI\n",
    "\n",
    "def run():\n",
    "    iter_num = 25\n",
    "    G = read_net(\"data\", \"dolphins\")\n",
    "    algs = {\n",
    "        \"Louvain\": algorithms.louvain,\n",
    "        \"Infomap\": algorithms.infomap,\n",
    "        \"Walktrap\": algorithms.walktrap\n",
    "    }\n",
    "    for algo_name in algs:\n",
    "        print('ALGORITHM:', algo_name)\n",
    "        nmi = compare_on_dolphins(G, algs[algo_name], iter_num)\n",
    "        print('======================'*3)\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq1PCnJufT6S"
   },
   "source": [
    "## 3. Peers, ties and the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86dlNEm9fdZ3"
   },
   "outputs": [],
   "source": [
    "def leiden(G, node_pairs):\n",
    "    coms = algorithms.leiden(G)\n",
    "    C = dict()\n",
    "    for i in range(len(coms.communities)):\n",
    "        for node in coms.communities[i]:\n",
    "            C[node] = i\n",
    "    part_G = community_louvain.induced_graph(C, G)\n",
    "\n",
    "    scores = []\n",
    "    for n1, n2 in node_pairs:\n",
    "        score = 0\n",
    "        if C[n1] == C[n2]:\n",
    "            try: \n",
    "                nc = len(coms.communities[C[n1]])\n",
    "                mc = part_G[C[n1]][C[n2]]['weight']\n",
    "                score = mc / (nc * (nc-1) / 2)\n",
    "            except KeyError:\n",
    "                score = 0\n",
    "        scores.append([n1, n2, score])\n",
    "    return scores\n",
    "\n",
    "def sample(G, p):\n",
    "    nodes = list(G.nodes())\n",
    "    N = int(G.number_of_edges()*p)\n",
    "    \n",
    "    Ln = []\n",
    "    while len(Ln) != N:\n",
    "        node1, node2 = random.choice(nodes), random.choice(nodes)\n",
    "        if not G.has_edge(node1, node2) and (node1, node2) not in Ln:\n",
    "            Ln.append((node1, node2))\n",
    "    \n",
    "    Lp = random.sample(list(G.edges()), N)\n",
    "    G.remove_edges_from(Lp)  \n",
    "    \n",
    "    return G, [*Ln, *Lp], len(Ln), N\n",
    "\n",
    "def AUC(G, algs):\n",
    "    G, nodes, l, N = sample(G.copy(), 0.1)\n",
    "\n",
    "    scores = []\n",
    "    for algo_name in algs:\n",
    "        predicted = list(algs[algo_name](G, nodes))\n",
    "        m1, m2 = 0, 0\n",
    "        for n in range(N):\n",
    "            s1 = random.sample(predicted[:l], 1)[0]\n",
    "            s2 = random.sample(predicted[l:], 1)[0]\n",
    "            if s2[2] > s1[2]:\n",
    "                m1 += 1\n",
    "            elif s1[2] == s2[2]:\n",
    "                m2 +=1\n",
    "        scores.append((m1 + m2/2) / N)\n",
    "    return np.array(scores)\n",
    "\n",
    "def AUC_runs(G, name, algs, n=10):\n",
    "    auc_l, auc_p, auc_a = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        scores = AUC(G, algs)\n",
    "        auc_l += scores[0]\n",
    "        auc_p += scores[1]\n",
    "        auc_a += scores[2]\n",
    "    print(name + ':')\n",
    "    print(\"  Leiden:\", auc_l/n)\n",
    "    print(\"  Preferential attachment:\", auc_p/n)\n",
    "    print(\"  Adamic adar index:\", auc_a/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GJ5lnYFpKOC",
    "outputId": "2e58dc13-b4af-4e1f-cbe1-745cb5874621"
   },
   "outputs": [],
   "source": [
    "algs = {\n",
    "    \"Leiden\": leiden,\n",
    "    \"Pref attachment\": nx.preferential_attachment,\n",
    "    \"Adamic adar index\": nx.adamic_adar_index\n",
    "}\n",
    "G = nx.Graph(nx.read_pajek(\"data/gnutella.net\")).to_undirected()\n",
    "AUC_runs(G, \"Gnutella\", algs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkE4AKlgp0n9",
    "outputId": "4bdd6d11-4eaf-4ba3-e50c-1886906cbcc5"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph(nx.read_pajek(\"data/circles.net\")).to_undirected()\n",
    "AUC_runs(G, \"Facebook\", algs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lG-wyKxgp54z",
    "outputId": "f8695cae-691d-4d6f-d74d-080e9e272f41"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph(nx.read_pajek(\"data/nec.net\")).to_undirected()\n",
    "AUC_runs(G, \"Internet\", algs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QG8tpJH2qIVh",
    "outputId": "03c07c14-a5c4-4b37-80b5-b67ff7c270aa"
   },
   "outputs": [],
   "source": [
    "G = nx.gnm_random_graph(25000, 125000)\n",
    "AUC_runs(G, \"Random\", algs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I17TCfnMq_R8"
   },
   "source": [
    "## 4. Get at least 70% right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfZ-CjuNq7H_"
   },
   "outputs": [],
   "source": [
    "def read_and_split(filepath):\n",
    "    G = nx.Graph() \n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "    f.readline()\n",
    "    test = []\n",
    "    for line in f:\n",
    "        if line.startswith(\"*\"):\n",
    "            continue\n",
    "\n",
    "        l = line.split()\n",
    "        if len(l) == 3:\n",
    "        if l[1][-3:-1] == '13':\n",
    "            G.add_node(int(l[0]))\n",
    "            test.append([int(l[0]), l[2]])\n",
    "        else:\n",
    "            G.add_node(int(l[0]), label=l[2])\n",
    "        else:\n",
    "        G.add_edge(int(l[0]), int(l[1]))\n",
    "\n",
    "    return G, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCPa7Gr5q7pb",
    "outputId": "e262f80c-9457-4a89-9a16-bef62e3eeb67"
   },
   "outputs": [],
   "source": [
    "G, test = read_and_split(\"data/aps_2008_2013.net\")\n",
    "iter_num = 10\n",
    "acc = 0\n",
    "for _ in range(iter_num):\n",
    "    #predicted = node_classification.harmonic_function(G)\n",
    "    predicted = node_classification.local_and_global_consistency(G)\n",
    "    count = 0\n",
    "    for (node, label) in test:\n",
    "        if predicted[node-1] == label:\n",
    "        count += 1\n",
    "\n",
    "    acc += count\n",
    "acc /= len(test)*iter_num\n",
    "print(\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
